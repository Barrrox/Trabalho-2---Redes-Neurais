# -*- coding: utf-8 -*-
"""Main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1anyVn8cjzlXelGme8SQEf-Axg2DwKUkw

# Classificação de obras de arte por movimento artístico

Autores: Ellen Brzozoski, João Silva, Lóra, Matheus Barros

# Imports
"""

import numpy as np
from random import randint
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input
from tensorflow.keras.utils import to_categorical
from time import time

"""# Funções auxiliares

## FormatImage

A função formatImage recebe uma imagem desformatada como parametro e recorta ela para ter um tamanho fixo definido.
"""

"""Carregar base de dados"""


def treinar_modelo(TAM_TESTES, QNT_EPOCAS):
  
  inicio = time()

  # Carrega o conjunto de dados
  x_train = np.load("imagens_treino.npy")
  y_train = np.load("labels_treino.npy")

  print(f"Tempo = {time() - inicio:2f}s : Dados de treino carregados")

  x_test = []
  y_test = []
  for _ in range(int(len(y_train)*TAM_TESTES)):
    imagem_index = randint(0, len(y_train) - 1)
    x_test.append(x_train[imagem_index])
    y_test.append(y_train[imagem_index])

  print(f"Tempo = {time() - inicio:2f}s : Dados de teste criados")

  # Transformando para numpy array para normalizar depois
  x_test = np.array(x_test)
  y_test = np.array(y_test)

  print(f"Tempo = {time() - inicio:2f}s : Conversão concluida")

  # lista de matrizes de pixel rgb

  # Normaliza os valores dos pixels para que fiquem entre 0 e 1
  x_train = x_train / 255.0
  x_test = x_test / 255.0

  print(f"Tempo = {time() - inicio:2f}s : Pixels normalizados entre 0 e 1")

  # Converte os rótulos (labels) para categorias (one-hot encoding)
  y_train = to_categorical(y_train, 9)
  y_test = to_categorical(y_test, 9)

  print(f"Tempo = {time() - inicio:2f}s : Rótulos covertidos para categorias")

  #2. Definindo o Modelo e Treinando

  model = Sequential([
    Input(shape=(255, 255, 3)), # Define o formato da entrada
    Conv2D(32, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(9, activation='softmax')
  ])




  # Compila o modelo
  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

  print(f"Tempo = {time() - inicio:2f}s : Modelo compilado")

  # Treina o modelo
  model.fit(x_train, y_train, epochs=QNT_EPOCAS, validation_data=(x_test, y_test))
  # Validarion_data serve só para caluclar val_accuracy e val_loss

  print(f"Tempo = {time() - inicio:2f}s : Modelo treinado")


  #3. Salvando o Modelo e os Pesos
  # Salva o modelo completo (arquitetura + pesos)

  model.save('model.keras')

  print(f"Tempo = {time() - inicio:2f}s : Modelo salvo")


def main():
	
  # Tamanho do conjunto de dados de testes em relação ao de treino
  # Ex: se TAM_TESTES = 0.16 então o conjunto de testes terá 16% do tamanho
  # do conjunto de treino
  TAM_TESTES = 1/6

  QNT_EPOCAS = 1

  treinar_modelo(TAM_TESTES, QNT_EPOCAS)



if __name__ == "__main__":
  main()